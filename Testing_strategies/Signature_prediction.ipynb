{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 16:32:15.812632: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import iisignature\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from Backtesting.Create_dataframes import CreateDataframe\n",
    "\n",
    "from Brokers.Alpaca.Alpaca_keyes import API_KEY, SECRET_KEY\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data and instead of predictiong five numbers, just predict one over the 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_account = 10000\n",
    "commission_fee = 0.01\n",
    "slippage_cost = 0.1\n",
    "\n",
    "create_df = CreateDataframe()\n",
    "\n",
    "start_date_train = datetime(2023, 1, 1) \n",
    "end_date_train = datetime(2025, 1, 1)\n",
    "\n",
    "data = create_df.Alpaca(\n",
    "    api_key=API_KEY,\n",
    "    secret_key=SECRET_KEY,\n",
    "    start_date=start_date_train,\n",
    "    end_date=end_date_train,\n",
    "    interval=TimeFrame(amount = 1, unit = TimeFrameUnit.Hour),\n",
    "    asset_list=\"TSLA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = data['timestamp'].dt.date  # Extract the date part\n",
    "unique_days = {day: i for i, day in enumerate(sorted(data['date'].unique()))}\n",
    "data['day'] = data['date'].map(unique_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = data.groupby(\"day\").agg(\n",
    "    close=(\"close\", \"last\")\n",
    ")\n",
    "\n",
    "output_data[\"return\"] = output_data[\"close\"].pct_change(periods=5) #periods=n\n",
    "output_data[\"state\"] = np.where(output_data[\"return\"] >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leadlag(X, use_time = False):\n",
    "   if (not use_time):\n",
    "       lead = []\n",
    "       lag = []\n",
    "       for val_lag, val_lead in zip(X[:-1], X[1:]):\n",
    "           lead.append(val_lag)\n",
    "           lag.append(val_lag)\n",
    "           lead.append(val_lead)\n",
    "           lag.append(val_lag)\n",
    "       lead.append(X[-1])\n",
    "       lag.append(X[-1])\n",
    "       return np.c_[lead, lag]\n",
    "   else:\n",
    "       lead = []\n",
    "       lag = []\n",
    "       t = []\n",
    "       time = 0\n",
    "       t.append(time)\n",
    "       lag.append(X[0])\n",
    "       lead.append(X[0])\n",
    "       for val_lag, val_lead in zip(X[:-1], X[1:]):\n",
    "           time += 1\n",
    "           t.append(time)\n",
    "           lead.append(val_lag)\n",
    "           lag.append(val_lag)\n",
    "           t.append(time)\n",
    "           lead.append(val_lead)\n",
    "           lag.append(val_lag)\n",
    "           t.append(time)\n",
    "           lead.append(val_lead)\n",
    "           lag.append(val_lead)\n",
    "       return np.c_[lead, lag, t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "X_list = []\n",
    "\n",
    "n_days = len(output_data)\n",
    "for i in range(n_days - 30 - 5):\n",
    "    window = data[(data[\"day\"] >= i)&(data[\"day\"] < i + 30)]\n",
    "    path = window[\"close\"].to_numpy()\n",
    "    ll_path = leadlag(path)\n",
    "    x = iisignature.sig(ll_path, 10)\n",
    "    X_list.append(x.reshape(1, -1))\n",
    "\n",
    "X = np.vstack(X_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = []\n",
    "\n",
    "for i in range(31, n_days-4):\n",
    "    window = output_data[(output_data.index >= i)&(output_data.index < i + 5)]\n",
    "    res = window[\"state\"].to_numpy()[-1] # .reshape(1, -1)\n",
    "    y_list.append(res)\n",
    "\n",
    "y = np.vstack(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X_train)\n",
    "sigma2 = np.std(X_train)\n",
    "\n",
    "X_train = (X_train - mu) / sigma2\n",
    "X_test = (X_test - mu) / sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0191 - loss: 1.0254      \n",
      "Epoch 2/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0610 - loss: 1.0111 \n",
      "Epoch 3/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0620 - loss: 1.0009 \n",
      "Epoch 4/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0606 - loss: 0.9982 \n",
      "Epoch 5/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0512 - loss: 1.0376 \n",
      "Epoch 6/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0562 - loss: 0.9727 \n",
      "Epoch 7/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0485 - loss: 0.9689 \n",
      "Epoch 8/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0360 - loss: 0.9807 \n",
      "Epoch 9/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0532 - loss: 0.9496 \n",
      "Epoch 10/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0711 - loss: 0.9356 \n",
      "Epoch 11/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0714 - loss: 0.9320 \n",
      "Epoch 12/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0592 - loss: 0.9651 \n",
      "Epoch 13/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0573 - loss: 0.9647 \n",
      "Epoch 14/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0418 - loss: 0.9612 \n",
      "Epoch 15/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0662 - loss: 0.9473  \n",
      "Epoch 16/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0538 - loss: 0.9332     \n",
      "Epoch 17/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0402 - loss: 0.9477     \n",
      "Epoch 18/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0462 - loss: 0.9513 \n",
      "Epoch 19/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0555 - loss: 0.9429 \n",
      "Epoch 20/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0578 - loss: 0.9166 \n",
      "Epoch 21/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0385 - loss: 0.9661     \n",
      "Epoch 22/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0425 - loss: 0.9506     \n",
      "Epoch 23/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0545 - loss: 0.9106 \n",
      "Epoch 24/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0539 - loss: 0.9334 \n",
      "Epoch 25/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0457 - loss: 0.9751     \n",
      "Epoch 26/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0524 - loss: 0.9339 \n",
      "Epoch 27/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0536 - loss: 0.9268 \n",
      "Epoch 28/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0606 - loss: 0.9042 \n",
      "Epoch 29/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0613 - loss: 0.9218 \n",
      "Epoch 30/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0559 - loss: 0.8978 \n",
      "Epoch 31/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0570 - loss: 0.8898 \n",
      "Epoch 32/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0588 - loss: 0.8938 \n",
      "Epoch 33/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0416 - loss: 0.9309     \n",
      "Epoch 34/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0521 - loss: 0.8519 \n",
      "Epoch 35/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0635 - loss: 0.8507 \n",
      "Epoch 36/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0630 - loss: 0.8938 \n",
      "Epoch 37/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0641 - loss: 0.8733 \n",
      "Epoch 38/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0729 - loss: 0.8743 \n",
      "Epoch 39/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0565 - loss: 0.8770 \n",
      "Epoch 40/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0632 - loss: 0.8775 \n",
      "Epoch 41/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0573 - loss: 0.8854 \n",
      "Epoch 42/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0798 - loss: 0.8570 \n",
      "Epoch 43/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0849 - loss: 0.8631 \n",
      "Epoch 44/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0574 - loss: 0.8861 \n",
      "Epoch 45/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0773 - loss: 0.8840 \n",
      "Epoch 46/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0699 - loss: 0.8961 \n",
      "Epoch 47/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0776 - loss: 0.8935 \n",
      "Epoch 48/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0623 - loss: 0.9320 \n",
      "Epoch 49/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0766 - loss: 0.8770 \n",
      "Epoch 50/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0683 - loss: 0.9153 \n",
      "Epoch 51/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0796 - loss: 0.8571 \n",
      "Epoch 52/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0746 - loss: 0.8565 \n",
      "Epoch 53/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0766 - loss: 0.8384 \n",
      "Epoch 54/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0605 - loss: 0.8910 \n",
      "Epoch 55/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0897 - loss: 0.8495 \n",
      "Epoch 56/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0655 - loss: 0.9258     \n",
      "Epoch 57/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0807 - loss: 0.8754 \n",
      "Epoch 58/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0859 - loss: 0.8720 \n",
      "Epoch 59/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0928 - loss: 0.8890 \n",
      "Epoch 60/60\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0576 - loss: 0.8737 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x143270a30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=60, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97970814]\n",
      " [ 0.06515748]\n",
      " [ 0.06757198]\n",
      " [ 0.04278886]\n",
      " [ 0.07348257]\n",
      " [ 0.06611477]\n",
      " [ 0.02587664]\n",
      " [ 0.06781615]\n",
      " [ 0.05404393]\n",
      " [-0.39549646]\n",
      " [-0.5797886 ]\n",
      " [ 0.06121916]\n",
      " [ 0.05579532]\n",
      " [ 0.05374987]\n",
      " [-0.68652815]\n",
      " [ 0.06683671]\n",
      " [ 0.18311624]\n",
      " [ 0.06565211]\n",
      " [ 0.0205707 ]\n",
      " [ 1.        ]\n",
      " [ 0.05769522]\n",
      " [ 0.06781457]\n",
      " [ 1.        ]\n",
      " [ 0.06376   ]\n",
      " [ 0.06753631]\n",
      " [ 0.81764317]\n",
      " [ 0.9970899 ]\n",
      " [ 1.        ]\n",
      " [ 0.06027663]\n",
      " [ 0.06725264]\n",
      " [-0.21700233]\n",
      " [ 0.06558643]\n",
      " [ 0.05762975]\n",
      " [ 0.00900199]\n",
      " [ 0.07078669]\n",
      " [-0.30146825]\n",
      " [ 0.05943384]\n",
      " [ 0.07812159]\n",
      " [ 0.9999909 ]\n",
      " [ 0.06749102]\n",
      " [-0.00586793]\n",
      " [ 0.02054969]\n",
      " [ 0.06817452]\n",
      " [ 0.06716318]\n",
      " [-0.61797655]\n",
      " [-0.6990355 ]\n",
      " [ 1.        ]\n",
      " [ 0.04161856]\n",
      " [-0.52321804]\n",
      " [ 0.067549  ]\n",
      " [ 0.05897683]\n",
      " [ 0.07649443]\n",
      " [-0.92270684]\n",
      " [ 0.06061395]\n",
      " [ 0.02280493]\n",
      " [-0.73565775]\n",
      " [ 0.05741199]\n",
      " [ 1.        ]\n",
      " [ 0.06637125]\n",
      " [ 0.06743866]\n",
      " [-0.8492505 ]\n",
      " [ 0.06450608]\n",
      " [ 0.02816685]\n",
      " [ 0.06488132]\n",
      " [ 1.        ]\n",
      " [ 0.03905158]\n",
      " [ 0.06650814]\n",
      " [ 0.06762065]\n",
      " [ 0.06568889]\n",
      " [ 0.0638688 ]\n",
      " [ 0.9933265 ]\n",
      " [ 0.03808055]\n",
      " [ 0.0371932 ]\n",
      " [ 0.06753153]\n",
      " [ 0.99855185]\n",
      " [ 0.06687409]\n",
      " [ 0.06713893]\n",
      " [ 0.06201575]\n",
      " [-0.59543663]\n",
      " [ 0.06789977]\n",
      " [ 0.06419015]\n",
      " [ 1.        ]\n",
      " [ 0.02700964]\n",
      " [ 0.00121887]\n",
      " [-0.71414536]\n",
      " [ 0.05963548]\n",
      " [ 0.06110469]\n",
      " [ 0.05843716]\n",
      " [ 0.0468032 ]\n",
      " [ 0.04642747]\n",
      " [ 0.06433188]\n",
      " [-0.16501124]\n",
      " [ 0.06611247]\n",
      " [ 0.04682013]\n",
      " [-0.62592894]\n",
      " [-0.01855828]\n",
      " [-0.40092185]\n",
      " [ 0.02768262]\n",
      " [ 1.        ]\n",
      " [ 0.02098626]\n",
      " [ 0.06739491]\n",
      " [ 0.06795467]\n",
      " [ 0.0678486 ]\n",
      " [ 0.06785645]\n",
      " [ 1.        ]\n",
      " [ 0.06808539]\n",
      " [ 0.06486869]\n",
      " [ 1.        ]\n",
      " [ 0.06330613]\n",
      " [ 0.06791537]\n",
      " [ 0.07995682]\n",
      " [ 0.9964878 ]\n",
      " [ 0.02801369]\n",
      " [ 0.0667262 ]\n",
      " [ 0.06792732]\n",
      " [-0.11276011]\n",
      " [ 0.06689999]\n",
      " [ 1.        ]\n",
      " [ 0.06773257]\n",
      " [ 0.06784677]\n",
      " [-0.04332264]\n",
      " [ 0.02280836]\n",
      " [ 0.07408849]\n",
      " [ 0.05802251]\n",
      " [ 0.07759692]\n",
      " [ 0.06285716]\n",
      " [ 0.06194831]\n",
      " [ 0.06759689]\n",
      " [ 0.07338504]\n",
      " [ 0.06749001]\n",
      " [ 0.06739263]\n",
      " [ 0.06726937]\n",
      " [ 0.05863701]\n",
      " [ 0.05841309]\n",
      " [-0.15792525]\n",
      " [ 0.02653858]\n",
      " [ 0.06731074]\n",
      " [ 0.00581566]\n",
      " [-0.00910088]\n",
      " [ 0.30606642]\n",
      " [ 0.0455922 ]\n",
      " [ 1.        ]\n",
      " [ 0.06402206]\n",
      " [ 0.06796553]\n",
      " [ 0.04800352]\n",
      " [ 0.03789676]\n",
      " [-0.53394806]\n",
      " [-0.00724412]\n",
      " [ 0.06323011]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [False]\n",
      " [ True]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(pred - y_test) < 0.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
